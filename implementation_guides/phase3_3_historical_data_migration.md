# Phase 3.3: Historical Data Migration (Tasks 3.3.1-3.3.11)
## REdI Trolley Audit System

**Version:** 1.0
**Date:** January 2026
**Estimated Duration:** 2-3 weeks
**Target Users:** System Administrators, Data Stewards

---

## Executive Summary

Phase 3.3 Historical Data Migration imports and validates historical audit data from 2023 and 2024 Microsoft Forms exports into the new SharePoint-based system. This guide provides a complete methodology for data analysis, field mapping, Power Query transformation, and validation procedures.

The migration process consists of:
- **2023 Data Migration** (Tasks 3.3.1-3.3.5): 75 audit records from Microsoft Forms
- **2024 Data Migration** (Tasks 3.3.6-3.3.10): 76 audit records from Microsoft Forms
- **Post-Migration Updates** (Task 3.3.11): Location master table synchronization

All historical data must be validated against the new schema before import to ensure data integrity and compliance score accuracy.

---

## Part 1: Data Analysis Methodology

### 1.1 Pre-Migration Checklist

Before beginning any migration work, verify the following prerequisites are complete:

| Item | Status | Owner |
|------|--------|-------|
| All Phase 1 SharePoint lists created | Required | Admin |
| All Phase 1 seed data imported | Required | Admin |
| Phase 2 Audit, AuditDocuments, AuditCondition, AuditChecks, AuditEquipment lists created | Required | Admin |
| Location master list populated (76 active locations) | Required | Admin |
| Equipment master list populated (89 items) | Required | Admin |
| 2023 Microsoft Forms export acquired | Required | Data Steward |
| 2024 Microsoft Forms export acquired | Required | Data Steward |
| Power Query desktop installed (Excel or Power BI Desktop) | Required | Admin |
| Test SharePoint site for UAT migration | Recommended | Admin |
| Data backup of historical exports | Recommended | Data Steward |

### 1.2 Historical Data Format Assessment

**2023 Data Source: Microsoft Forms Export**

Expected columns from Forms response export:
```
- Id (auto-generated by Forms)
- Start time (DateTime)
- Completion time (DateTime)
- Email (typically "anonymous")
- Auditor Name (free text)
- Clinical Area (free text - inconsistent naming)
- Service Line/Directorate (Choice field - 7 options)
- Other Directorate (free text if "Other" selected)
- Check Record Present (Choice: Yes - current / Yes - old / No)
- Checking Guidelines Present (Choice: Yes - current / Yes - old / No)
- BLS Poster Present (Choice: Yes / No)
- Equipment List Present (Choice: Yes / No)
- All Items Stocked (Choice: Yes / No)
- Additional Items Found (Choice: Yes / No)
- Items Added/Missing (String - free text)
- Outside Check Count (String - numeric or "Not Available")
- Inside Check Count (String - numeric or "Not Available")
- Rubber Bands Present (Choice: Yes / No)
- Trolley Clean (Choice: Yes / No)
- Trolley Working Order (Choice: Yes / No)
- Issue Details (String - free text)
- O2 Tubing Correct (Choice: Yes / No)
- INHALO Cylinder OK (Choice: Yes / No)
```

**2024 Data Source: Microsoft Forms Export**

Same structure as 2023 with potential minor question wording variations.

### 1.3 Data Quality Issues to Address

Historical data has known data quality issues that must be cleaned during migration:

#### Issue #1: Inconsistent Location Naming

**Problem:** Clinical Area field contains inconsistent naming making location matching difficult

**Examples:**
- "7A North" vs "7AN" vs "7A north"
- "5c" vs "5C" vs "5C beds 1-18"
- "Cath Lab 1" vs "Cath lab procedure room 1"
- "ED Cold" vs "ED-Cold"

**Solution:** Create a location name mapping table (Section 1.4) to standardize before import.

**Impact:** Without this, ~15-20% of records fail to link to correct Location master record.

#### Issue #2: Mixed Check Count Data Types

**Problem:** Outside/Inside check counts contain mixed data formats preventing direct numeric import

**Examples:**
- "31" (valid number)
- "Not Available" (text marker)
- "NUM off ward" (text with abbreviation)
- "21/21" (ratio format)
- Empty/blank cells

**Solution:** Parse with conditional logic in Power Query, create boolean CountNotAvailable field.

**Impact:** Without this, numeric calculations fail and compliance scores cannot be computed.

#### Issue #3: Missing Required Fields

**Problem:** Not all response fields are populated for every record

**Examples:**
- Some auditor names blank
- Some clinical areas not filled
- Equipment count data missing
- Issue descriptions blank for trolleys in good condition

**Solution:** Flag missing required fields during validation phase, allow optional fields to remain blank.

**Impact:** Records with missing critical fields (Location, AuditorName, AuditDateTime) should be flagged for manual review before import.

#### Issue #4: Date Format Variations

**Problem:** Start time and Completion time may use different date formats depending on Forms locale

**Examples:**
- "1/15/2023 2:30 PM"
- "15/01/2023 14:30"
- "2023-01-15 14:30:00"

**Solution:** Power Query automatically detects and converts to standard DateTime format.

**Impact:** Without conversion, date calculations (DaysSinceLastAudit) will fail.

#### Issue #5: Boolean Value Inconsistencies

**Problem:** Yes/No responses may have variations

**Examples:**
- "Yes" vs "yes" vs "YES"
- "No" vs "no" vs "NO"
- "1" vs "0" (from some Forms exports)
- Empty = No (implied)

**Solution:** Standardize to true/false boolean in Power Query with case-insensitive matching.

**Impact:** Compliance score calculations require correct boolean values.

#### Issue #6: Documentation Status Values

**Problem:** Choice fields for documentation status may use inconsistent terminology

**Expected values:** "Current", "Old", "None"

**Actual variations:**
- "Yes - current" vs "Current"
- "Yes - old" vs "Old"
- "No" vs "None"
- Empty cells
- Misspellings ("Curent", "Olde")

**Solution:** Create standardized value mapping in Power Query.

**Impact:** Documentation subscore calculation requires exact field values.

### 1.4 Location Name Mapping Table

Create a CSV file mapping historical location names to master Location list department names. This is critical for data integrity.

**File:** `location_name_mapping.csv`

```csv
HistoricalName,MasterLocationName,ServiceLine,Building,MatchConfidence
7A North,7A North,Surgical & Perioperative Services,Ned Hanlon Building,High
7AN,7A North,Surgical & Perioperative Services,Ned Hanlon Building,High
7A north,7A North,Surgical & Perioperative Services,Ned Hanlon Building,High
5c,5C beds 1-18,Cancer Care Services,Joyce Tweddell Building,Medium
5C,5C beds 1-18,Cancer Care Services,Joyce Tweddell Building,High
5C beds,5C beds 1-18,Cancer Care Services,Joyce Tweddell Building,High
Cath Lab 1,Cath Lab procedure room 1,Internal Medicine Services,James Mayne Building,Medium
Cath lab procedure room 1,Cath Lab procedure room 1,Internal Medicine Services,James Mayne Building,High
ED Cold,ED-Cold,Internal Medicine Services,James Mayne Building,High
ED-Cold,ED-Cold,Internal Medicine Services,James Mayne Building,High
```

**Instructions for completing this mapping:**

1. Export unique Clinical Area values from 2023 Forms export: `SELECT DISTINCT [Clinical Area] FROM 2023Data`
2. For each unique name, manually find the matching Location in the master list
3. Assign MatchConfidence: High (exact/clear match), Medium (probable match), Low (uncertain)
4. Flag Low-confidence matches for manual review before import
5. Save as CSV and import into Power Query as reference table

---

## Part 2: Field Mapping Documentation

### 2.1 2023 Audit Data Field Mapping

This table shows how each 2023 Forms field maps to the new SharePoint schema:

| Forms Field | Source Data Type | Target Table | Target Column | Target Data Type | Transformation Notes |
|---|---|---|---|---|---|
| Start time | DateTime | Audit | StartedDateTime | DateTime | Direct mapping; convert to UTC if needed |
| Completion time | DateTime | Audit | CompletedDateTime | DateTime | Direct mapping; nullable if draft |
| Auditor Name | String(255) | Audit | AuditorName | String(100) | Trim whitespace; required field |
| Clinical Area | String(255) | Audit | Location (lookup) | Lookup | Use location_name_mapping.csv to standardize |
| Service Line/Directorate | String(50) | Audit | (derived from Location) | - | Populated via Location lookup, not directly mapped |
| Check Record Present | Choice | AuditDocuments | CheckRecordStatus | Choice | Map: "Yes - current"→"Current", "Yes - old"→"Old", "No"→"None" |
| Checking Guidelines Present | Choice | AuditDocuments | CheckGuidelinesStatus | Choice | Map: "Yes - current"→"Current", "Yes - old"→"Old", "No"→"None" |
| BLS Poster Present | Choice | AuditDocuments | BLSPosterPresent | Boolean | Map: "Yes"→true, "No"→false, empty→false |
| Equipment List Present | Choice | AuditDocuments | EquipmentListStatus | Choice | Map: "Yes - current"→"Current", "Yes - old"→"Old", "No"→"None" |
| All Items Stocked | Choice | AuditCondition | (see notes) | - | No direct mapping; see equipment section |
| Additional Items Found | String(255) | AuditCondition | ConditionNotes | Note | Optional; append to notes if present |
| Items Added/Missing | String(255) | AuditEquipment | ItemNotes (per item) | Note | Store in general condition notes; no item-level detail available |
| Outside Check Count | String(50) | AuditChecks | OutsideCheckCount | Integer | Parse numeric value; null if "Not Available" |
| Inside Check Count | String(50) | AuditChecks | InsideCheckCount | Integer | Parse numeric value; null if "Not Available" |
| Count Not Available (derived) | (Derived) | AuditChecks | CountNotAvailable | Boolean | true if either count = "Not Available" |
| Rubber Bands Present | Choice | AuditCondition | RubberBandsUsed | Boolean | Note: invert logic (Yes→true in original, but RubberBandsUsed=true is a problem) |
| Trolley Clean | Choice | AuditCondition | IsClean | Boolean | Map: "Yes"→true, "No"→false |
| Trolley Working Order | Choice | AuditCondition | IsWorkingOrder | Boolean | Map: "Yes"→true, "No"→false |
| Issue Details | String(255) | AuditCondition | IssueDescription | String(500) | Optional; only if IsWorkingOrder=false |
| O2 Tubing Correct | Choice | AuditCondition | O2TubingCorrect | Boolean | Map: "Yes"→true, "No"→false |
| INHALO Cylinder OK | Choice | AuditCondition | InhaloCylinderOK | Boolean | Map: "Yes"→true, "No"→false |
| (not in Forms) | - | Audit | SubmissionStatus | Choice | Set to "Submitted" for all historical records |
| (not in Forms) | - | Audit | AuditType | Choice | Set to "Comprehensive" for all historical records |
| (not in Forms) | - | AuditPeriod | (derived) | Lookup | Derive from Completion time year; create 2023 AuditPeriod if needed |
| Id | Integer | (not imported) | - | - | Source system identifier; create new IDs in SharePoint |

### 2.2 2024 Audit Data Field Mapping

The 2024 mapping is identical to 2023 with possible question wording variations:

| Forms Field | Source Data Type | Target Table | Target Column | Target Data Type | Transformation Notes |
|---|---|---|---|---|---|
| Start time | DateTime | Audit | StartedDateTime | DateTime | Direct mapping; convert to UTC if needed |
| Completion time | DateTime | Audit | CompletedDateTime | DateTime | Direct mapping; nullable if draft |
| Auditor Name | String(255) | Audit | AuditorName | String(100) | Trim whitespace; required field |
| Clinical Area | String(255) | Audit | Location (lookup) | Lookup | Use location_name_mapping.csv to standardize |
| Service Line/Directorate | String(50) | Audit | (derived from Location) | - | Populated via Location lookup, not directly mapped |
| (all other fields) | (same as 2023) | (same as 2023) | (same as 2023) | (same as 2023) | Refer to 2023 mapping table |

**Key Difference for 2024:** Ensure new 2024 AuditPeriod record is created with proper expected check count values.

### 2.3 Critical Mapping Rules

**Rule 1: Location Lookup is Mandatory**

Every audit record must link to a Location in the Location master list. Records that cannot be matched to a location will:
- Fail to import (if using SharePoint validation)
- Create data integrity issues in reporting
- Make compliance calculations impossible

**Action:** Use location_name_mapping.csv strictly. If a location name cannot be matched, flag for manual resolution before import.

**Rule 2: AuditPeriod Lookup is Mandatory**

Every audit record must reference an AuditPeriod. For historical data:
- 2023 records → 2023 AuditPeriod (create if not exists)
- 2024 records → 2024 AuditPeriod (likely already exists)

**Action:** Ensure both 2023 and 2024 AuditPeriod records exist with correct expected check counts before import.

**Rule 3: Boolean Standardization**

All Yes/No choices must be converted to true/false:
- Yes → true
- No → false
- Empty/null → false (for required fields), null (for optional)
- Case-insensitive matching required

**Action:** Use Power Query with Text.Lower() function for case normalization.

**Rule 4: Compliance Score Preservation**

Historical records do NOT have pre-calculated compliance scores. Compliance scores will be:
- Calculated using the new weighted formula (25% docs, 40% equipment, 15% condition, 20% checks)
- Generated during Power Automate import flow
- Stored in Audit.OverallCompliance

**Note:** This may differ from original Excel calculations. Document the difference for audit trail.

**Rule 5: Equipment-Level Detail NOT Available**

The 2023/2024 Forms did not capture equipment-level detail (only "All Items Stocked: Yes/No").

Therefore:
- AuditEquipment records will NOT be created during import
- Equipment compliance score will be marked as 100% (assumed all present if marked as stocked)
- If "All Items Stocked: No", create a single note, not individual item records

**Action:** Document this limitation in migration validation report.

---

## Part 3: Power Query Transformation Scripts

Power Query (M language) scripts for transforming historical data. These scripts handle all data quality issues identified in Section 1.3.

### 3.1 Setup: Import and Prepare Source Data

**Step 1: Import Forms Export CSV into Power Query**

In Excel or Power BI Desktop:
1. Get Data → From Text/CSV
2. Select 2023_Audit_Export.csv
3. Click Transform Data
4. Power Query opens with data preview

**Step 2: Detect Data Types**

Power Query should auto-detect, but verify:
- Start time / Completion time: DateTime
- Auditor Name: Text
- Clinical Area: Text
- Numeric fields: Text (will convert)
- Choice fields: Text (will standardize)

### 3.2 Power Query Script: 2023 Data Transformation

Create a new query called `Transform_2023_Audit_Data`

**Complete M Language Script:**

```powerquery
let
    // Step 1: Import raw CSV
    Source = Csv.Document(File.Contents("C:\temp\2023_Audit_Export.csv"), [Delimiter=",", Encoding=1252, QuoteStyle=QuoteStyle.None]),

    // Step 2: Promote headers
    PromotedHeaders = Table.PromoteHeaders(Source, [PromoteAllScalars=true]),

    // Step 3: Clean column names (remove leading/trailing spaces)
    CleanedColumns = Table.TransformColumnNames(PromotedHeaders, Text.Trim),

    // Step 4: Standardize Clinical Area names using lookup table
    LocationMappingTable = Table.FromRows(
        {
            {"7A North", "7A North"},
            {"7AN", "7A North"},
            {"7A north", "7A North"},
            {"5c", "5C beds 1-18"},
            {"5C", "5C beds 1-18"},
            {"5C beds", "5C beds 1-18"},
            {"Cath Lab 1", "Cath Lab procedure room 1"},
            {"Cath lab procedure room 1", "Cath Lab procedure room 1"},
            {"ED Cold", "ED-Cold"},
            {"ED-Cold", "ED-Cold"}
            // ... add all location mappings from mapping table
        },
        type table [HistoricalName=text, MasterLocationName=text]
    ),

    StandardizedLocations = Table.AddColumn(
        CleanedColumns,
        "LocationStandardized",
        each Table.SelectRows(LocationMappingTable, each [HistoricalName] = [Clinical Area])[MasterLocationName]{0}?,
        type text
    ),

    // Step 5: Handle missing locations with original value if no mapping found
    LocationFinal = Table.AddColumn(
        StandardizedLocations,
        "LocationName",
        each if [LocationStandardized] <> null then [LocationStandardized] else [Clinical Area],
        type text
    ),

    // Step 6: Convert and standardize datetime fields
    DateConverted = Table.TransformColumnTypes(LocationFinal, {{"Start time", type datetime}, {"Completion time", type datetime}}),

    // Step 7: Create derived AuditPeriod field from Completion time
    AddAuditPeriod = Table.AddColumn(
        DateConverted,
        "AuditPeriodYear",
        each Date.Year([Completion time]),
        type number
    ),

    AddAuditPeriodName = Table.AddColumn(
        AddAuditPeriod,
        "AuditPeriodName",
        each "Year " & Text.From([AuditPeriodYear]),
        type text
    ),

    // Step 8: Standardize boolean fields
    StandardizeBooleanYesNo = (fieldValue) =>
        if fieldValue = null or fieldValue = ""
        then false
        else if Text.Lower(Text.Trim(fieldValue)) = "yes"
        then true
        else false,

    // Step 9: Transform Check Record Present (Choice: Yes-current, Yes-old, No)
    TransformCheckRecord = Table.AddColumn(
        AddAuditPeriodName,
        "CheckRecordStatus",
        each
            if [Check Record Present] = null or [Check Record Present] = ""
            then "None"
            else if Text.Contains(Text.Lower([Check Record Present]), "current")
            then "Current"
            else if Text.Contains(Text.Lower([Check Record Present]), "old")
            then "Old"
            else "None",
        type text
    ),

    // Step 10: Transform Guidelines Present
    TransformGuidelines = Table.AddColumn(
        TransformCheckRecord,
        "CheckGuidelinesStatus",
        each
            if [Checking Guidelines Present] = null or [Checking Guidelines Present] = ""
            then "None"
            else if Text.Contains(Text.Lower([Checking Guidelines Present]), "current")
            then "Current"
            else if Text.Contains(Text.Lower([Checking Guidelines Present]), "old")
            then "Old"
            else "None",
        type text
    ),

    // Step 11: Transform BLS Poster (boolean)
    TransformBLSPoster = Table.AddColumn(
        TransformGuidelines,
        "BLSPosterPresent",
        each StandardizeBooleanYesNo([BLS Poster Present]),
        type logical
    ),

    // Step 12: Transform Equipment List Present
    TransformEquipmentList = Table.AddColumn(
        TransformBLSPoster,
        "EquipmentListStatus",
        each
            if [Equipment List Present] = null or [Equipment List Present] = ""
            then "None"
            else if Text.Contains(Text.Lower([Equipment List Present]), "current")
            then "Current"
            else if Text.Contains(Text.Lower([Equipment List Present]), "old")
            then "Old"
            else "None",
        type text
    ),

    // Step 13: Parse Outside Check Count (handle "Not Available", numeric, ratio formats)
    ParseOutsideCheckCount = Table.AddColumn(
        TransformEquipmentList,
        "OutsideCheckCountParsed",
        each
            if [Outside Check Count] = null or [Outside Check Count] = ""
            then null
            else if Text.Lower(Text.Trim([Outside Check Count])) = "not available"
            then null
            else if Text.Contains([Outside Check Count], "/")
            then
                let parts = Text.Split([Outside Check Count], "/") in
                try Value.FromText(parts{0}) otherwise null
            else
                try Value.FromText(Text.Trim([Outside Check Count])) otherwise null,
        type number
    ),

    // Step 14: Parse Inside Check Count (same as outside)
    ParseInsideCheckCount = Table.AddColumn(
        ParseOutsideCheckCount,
        "InsideCheckCountParsed",
        each
            if [Inside Check Count] = null or [Inside Check Count] = ""
            then null
            else if Text.Lower(Text.Trim([Inside Check Count])) = "not available"
            then null
            else if Text.Contains([Inside Check Count], "/")
            then
                let parts = Text.Split([Inside Check Count], "/") in
                try Value.FromText(parts{0}) otherwise null
            else
                try Value.FromText(Text.Trim([Inside Check Count])) otherwise null,
        type number
    ),

    // Step 15: Create CountNotAvailable flag
    AddCountNotAvailable = Table.AddColumn(
        ParseInsideCheckCount,
        "CountNotAvailable",
        each
            ([Outside Check Count] = "Not Available" or [Inside Check Count] = "Not Available")
            or ([OutsideCheckCountParsed] = null and [InsideCheckCountParsed] = null),
        type logical
    ),

    // Step 16: Transform Rubber Bands (inverse logic: used = problem)
    TransformRubberBands = Table.AddColumn(
        AddCountNotAvailable,
        "RubberBandsUsed",
        each StandardizeBooleanYesNo([Rubber Bands Present]),
        type logical
    ),

    // Step 17: Transform Trolley Clean
    TransformClean = Table.AddColumn(
        TransformRubberBands,
        "IsClean",
        each StandardizeBooleanYesNo([Trolley Clean]),
        type logical
    ),

    // Step 18: Transform Trolley Working Order
    TransformWorkingOrder = Table.AddColumn(
        TransformClean,
        "IsWorkingOrder",
        each StandardizeBooleanYesNo([Trolley Working Order]),
        type logical
    ),

    // Step 19: Handle Issue Description (only if not working)
    TransformIssueDesc = Table.AddColumn(
        TransformWorkingOrder,
        "IssueDescription",
        each
            if [IsWorkingOrder] = false and ([Issue Details] <> null and [Issue Details] <> "")
            then Text.Trim([Issue Details])
            else null,
        type text
    ),

    // Step 20: Transform O2 Tubing
    TransformO2Tubing = Table.AddColumn(
        TransformIssueDesc,
        "O2TubingCorrect",
        each StandardizeBooleanYesNo([O2 Tubing Correct]),
        type logical
    ),

    // Step 21: Transform INHALO Cylinder
    TransformInhalogo = Table.AddColumn(
        TransformO2Tubing,
        "InhaloCylinderOK",
        each StandardizeBooleanYesNo([INHALO Cylinder OK]),
        type logical
    ),

    // Step 22: Add static fields for all historical records
    AddSubmissionStatus = Table.AddColumn(
        TransformInhalogo,
        "SubmissionStatus",
        each "Submitted",
        type text
    ),

    AddAuditType = Table.AddColumn(
        AddSubmissionStatus,
        "AuditType",
        each "Comprehensive",
        type text
    ),

    // Step 23: Clean up unnecessary columns (keep only transformed fields)
    SelectColumns = Table.SelectColumns(AddAuditType,
        {
            "Start time",
            "Completion time",
            "Auditor Name",
            "LocationName",
            "AuditPeriodName",
            "CheckRecordStatus",
            "CheckGuidelinesStatus",
            "BLSPosterPresent",
            "EquipmentListStatus",
            "OutsideCheckCountParsed",
            "InsideCheckCountParsed",
            "CountNotAvailable",
            "RubberBandsUsed",
            "IsClean",
            "IsWorkingOrder",
            "IssueDescription",
            "O2TubingCorrect",
            "InhaloCylinderOK",
            "SubmissionStatus",
            "AuditType",
            "All Items Stocked"
        }
    ),

    // Step 24: Rename columns to match SharePoint field names
    RenameColumns = Table.RenameColumns(SelectColumns,
        {
            {"Start time", "StartedDateTime"},
            {"Completion time", "CompletedDateTime"},
            {"Auditor Name", "AuditorName"},
            {"LocationName", "LocationName"},
            {"AuditPeriodName", "AuditPeriodName"},
            {"OutsideCheckCountParsed", "OutsideCheckCount"},
            {"InsideCheckCountParsed", "InsideCheckCount"},
            {"All Items Stocked", "AllItemsStocked"}
        }
    ),

    // Step 25: Data quality validation - flag issues
    AddValidationFlags = Table.AddColumn(
        RenameColumns,
        "ValidationErrors",
        each
            let
                errors = {}
            in
                errors
                & (if [AuditorName] = null or [AuditorName] = "" then {"MissingAuditorName"} else {})
                & (if [LocationName] = null or [LocationName] = "" then {"MissingLocation"} else {})
                & (if [StartedDateTime] = null then {"MissingStartTime"} else {})
                & (if Number.From([OutsideCheckCount] ?? 0) > 93 then {"OutsideCountTooHigh"} else {})
                & (if Number.From([InsideCheckCount] ?? 0) > 4 then {"InsideCountTooHigh"} else {})
        ,
        type text
    ),

    // Final output table
    FinalTable = AddValidationFlags

in
    FinalTable
```

### 3.3 Power Query Script: 2024 Data Transformation

The 2024 script is identical to 2023 with these modifications:

```powerquery
// In Step 4, if 2024 forms added new location names, update LocationMappingTable
// Otherwise, entire script is identical to 2023

// Change this line:
AddAuditPeriodName = Table.AddColumn(
    AddAuditPeriod,
    "AuditPeriodName",
    each "Year " & Text.From([AuditPeriodYear]),
    type text
)

// To handle both 2023 and 2024:
// (Keep same, will be populated based on Completion time year)
```

### 3.4 Using the Power Query Scripts

**In Microsoft Excel:**

1. Open Power Query Editor
2. New Query → Blank Query
3. Copy the M script above into the formula bar
4. Replace file paths with actual locations
5. Click Done
6. Transform data preview will appear
7. Click "Load To..." and export to SharePoint

**In Power BI Desktop:**

1. Get Data → Other Sources → Blank Query
2. Paste M script
3. Click Done
4. Preview results
5. Close & Apply
6. Use Power Automate to push to SharePoint lists

**Alternative: Using Power Automate with Excel Connectors**

If Power Query is unavailable, create a Power Automate flow:
1. Trigger on Forms submission or manual start
2. Read Excel file with historical data
3. Apply transformations using Flow expressions
4. Create SharePoint list items
5. Run validation checks
6. Report errors

---

## Part 4: Validation Procedures

### 4.1 Pre-Import Validation Checklist

Before importing any transformed data, execute these validation checks:

#### V1.1: Data Completeness

**Check:** All required fields populated

| Field | Required | Rule | Sample Query |
|-------|----------|------|---|
| AuditorName | Yes | NOT NULL and LEN > 0 | `SELECT COUNT(*) WHERE AuditorName IS NULL` |
| LocationName | Yes | NOT NULL and exists in Location master | `SELECT COUNT(*) WHERE LocationName NOT IN (SELECT Title FROM Location)` |
| StartedDateTime | Yes | NOT NULL and valid date | `SELECT COUNT(*) WHERE StartedDateTime IS NULL` |
| CompletedDateTime | No | NULL or valid date | `SELECT COUNT(*) WHERE CompletedDateTime < StartedDateTime` |
| SubmissionStatus | Yes | Must be 'Submitted' | `SELECT COUNT(*) WHERE SubmissionStatus <> 'Submitted'` |

**Action:** If any record fails required field check, hold from import and flag for data steward review.

#### V1.2: Data Type Validation

**Check:** All fields converted to correct data types

```sql
-- DateTime fields
SELECT COUNT(*) WHERE StartedDateTime NOT BETWEEN '2023-01-01' AND '2024-12-31'
SELECT COUNT(*) WHERE CompletedDateTime < StartedDateTime

-- Boolean fields (should be true/false only)
SELECT COUNT(*) WHERE IsClean NOT IN (true, false, NULL)
SELECT COUNT(*) WHERE IsWorkingOrder NOT IN (true, false, NULL)

-- Numeric fields (check ranges)
SELECT COUNT(*) WHERE OutsideCheckCount > 93 OR OutsideCheckCount < 0
SELECT COUNT(*) WHERE InsideCheckCount > 4 OR InsideCheckCount < 0

-- Choice fields (should match allowed values)
SELECT COUNT(*) WHERE CheckRecordStatus NOT IN ('Current', 'Old', 'None')
SELECT COUNT(*) WHERE CheckGuidelinesStatus NOT IN ('Current', 'Old', 'None')
```

#### V1.3: Referential Integrity

**Check:** All lookup fields reference valid master records

```sql
-- Location lookup validation
SELECT COUNT(*)
FROM TransformedData t
LEFT JOIN Location l ON t.LocationName = l.Title
WHERE l.Title IS NULL

-- AuditPeriod lookup validation
SELECT COUNT(*)
FROM TransformedData t
LEFT JOIN AuditPeriod ap ON t.AuditPeriodName = ap.Title
WHERE ap.Title IS NULL
```

**Expected result:** 0 (zero mismatches)

**If mismatches found:**
1. Check location_name_mapping.csv is complete
2. Verify Location master list is current
3. Create any missing AuditPeriod records
4. Re-run transformation with updated mappings

#### V1.4: Duplicate Detection

**Check:** No duplicate audit records

```sql
-- Detect exact duplicates (same location, same datetime)
SELECT LocationName, StartedDateTime, COUNT(*) as Cnt
FROM TransformedData
GROUP BY LocationName, StartedDateTime
HAVING COUNT(*) > 1

-- Detect likely duplicates (same location, same day, similar time)
SELECT LocationName, CAST(StartedDateTime as DATE) as AuditDate, COUNT(*) as Cnt
FROM TransformedData
GROUP BY LocationName, CAST(StartedDateTime as DATE)
HAVING COUNT(*) > 1
```

**Expected result:** 0 (zero exact duplicates)

**If found:** Investigate - may indicate Forms duplicate submissions. Remove duplicates keeping record with latest completion time.

#### V1.5: Location Name Matching

**Check:** All location names successfully mapped

```sql
-- Show any unmapped locations
SELECT DISTINCT LocationName, COUNT(*) as RecordCount
FROM TransformedData
WHERE LocationName NOT IN (SELECT Title FROM Location)
ORDER BY LocationName
```

**Expected result:** 0 (zero unmapped)

**If found:** Update location_name_mapping.csv and re-run transformation.

**Acceptable exception:** If location was decommissioned after 2023/2024, create "Inactive" location record for historical reference.

#### V1.6: Date Range Validation

**Check:** All dates within expected ranges

```sql
-- 2023 data should have dates between 2023-01-01 and 2023-12-31
SELECT COUNT(*) as OutOfRange
FROM Transform_2023_Data
WHERE YEAR(CompletedDateTime) <> 2023

-- 2024 data should have dates between 2024-01-01 and 2024-12-31
SELECT COUNT(*) as OutOfRange
FROM Transform_2024_Data
WHERE YEAR(CompletedDateTime) <> 2024
```

**Expected result:** 0 (zero out-of-range)

#### V1.7: Check Count Validation

**Check:** Check counts are within realistic ranges

```sql
-- Outside checks should not exceed expected maximum
-- 24/7 location: max 3 checks/day × 365 days = 1095 per year
-- Weekday location: max 1 check/day × 260 working days = 260 per year

SELECT LocationName, OutsideCheckCount, InsideCheckCount, CountNotAvailable
FROM TransformedData
WHERE (OutsideCheckCount > 1100 AND CountNotAvailable = false)
   OR (InsideCheckCount > 52 AND CountNotAvailable = false)
ORDER BY OutsideCheckCount DESC

-- Inside checks should not exceed ~52 per year (one per week)
```

**Expected result:** Small number or zero; if large counts found, investigate:
- May be cumulative count instead of period count
- May be data entry error
- Flag for manual review

#### V1.8: Compliance Field Validation

**Check:** No pre-calculated compliance scores (should be null)

```sql
SELECT COUNT(*) as HasCompliance
FROM TransformedData
WHERE OverallCompliance IS NOT NULL
```

**Expected result:** 0 (zero with compliance scores)

**Reason:** Compliance scores will be calculated during Power Automate import flow using new weighted formula.

### 4.2 Import Quality Checks

During the import process, Power Automate should perform these checks:

#### Q1: Audit Record Creation

```
Power Automate Action: Create Audit Record

VALIDATION CHECKS:
- LocationId lookup succeeded (required)
- PeriodId lookup succeeded (required)
- StartedDateTime and CompletedDateTime set correctly
- SubmissionStatus = "Submitted"
- No duplicate audit for same Location + Period (warn but allow)

STOP IMPORT IF:
- Location lookup failed
- Period lookup failed
- Required fields missing

WARN IF:
- CompletedDateTime - StartedDateTime < 5 minutes (too fast)
- All items marked present with no comments (rubber stamp)
```

#### Q2: Child Record Creation

```
Power Automate Action: Create AuditDocuments Record

VALIDATION CHECKS:
- AuditId foreign key populated
- All choice fields have valid values (Current/Old/None)
- BLSPosterPresent is boolean

VALIDATION CHECKS: AuditCondition Record
- IsClean and IsWorkingOrder are boolean
- If IsWorkingOrder=false, IssueDescription should not be empty

VALIDATION CHECKS: AuditChecks Record
- OutsideCheckCount and InsideCheckCount are null or positive integers
- If CountNotAvailable=false, at least one count should not be null
```

#### Q3: Compliance Score Calculation

```
Power Automate Action: Calculate Compliance Score

FORMULA:
DocScore = (CheckRecordStatus + CheckGuidelinesStatus + BLSPosterPresent + EquipmentListStatus) / 4
  where Current=1, Old=0.5, None=0

EquipScore = (AllItemsStocked ? 1 : 0)
  NOTE: Historical data does not have item-level detail

CondScore = (IsClean + IsWorkingOrder + NOT(RubberBandsUsed) + O2TubingCorrect + InhaloCylinderOK) / 5

CheckScore = ((OutsideCheckCount / ExpectedOutside) + (InsideCheckCount / ExpectedInside)) / 2
  Capped at 1.0

OverallCompliance = (DocScore × 0.25) + (EquipScore × 0.40) + (CondScore × 0.15) + (CheckScore × 0.20)
Expressed as percentage (0-100)

VALIDATION:
- Result is between 0 and 100
- Store in Audit.OverallCompliance
```

#### Q4: Location Update

```
Power Automate Action: Update Location Record

ONLY IF this is the most recent audit for the location:

IF CompletedDateTime > Location.LastAuditDate THEN
  - Update Location.LastAuditDate = CompletedDateTime
  - Update Location.LastAuditCompliance = OverallCompliance
  - Update Location.DaysSinceLastAudit = calculated field
ELSE
  - Skip update (this is an older audit)
```

### 4.3 Post-Import Validation Report

After all data imported, generate a validation report with these metrics:

**Section 1: Import Summary**

```
2023 Audit Data Import Summary
==============================
Records attempted:        75
Records successfully imported: _____
Records failed:           _____
Records in UAT (not production): _____

Success rate: _____% (target: 100%)

2024 Audit Data Import Summary
==============================
Records attempted:        76
Records successfully imported: _____
Records failed:           _____
Records in UAT (not production): _____

Success rate: _____% (target: 100%)
```

**Section 2: Data Quality Issues Found**

```
Data Quality Issues Summary
===========================

Issue Category                Count    Examples                    Resolution
─────────────────────────────────────────────────────────────────────────────
Location name mismatches      ___     "7AN" → "7A North"         Fixed via mapping
Missing auditor names         ___     [list records]              Manual entry
Date conversion errors        ___     [list records]              Re-import
Invalid check counts          ___     [list records]              Manual review
Duplicate submissions         ___     [list records]              Removed duplicates
```

**Section 3: Location Coverage**

```
Location Audit Coverage
=======================

Total active locations:       76
Locations with 2023 audit:    ___ (target: 75)
Locations with 2024 audit:    ___ (target: 76)
Locations with both years:    ___ (target: 74+)

Locations missing 2023 audit:
- [list any locations]

Locations missing 2024 audit:
- [list any locations]
```

**Section 4: Compliance Score Distribution**

```
Compliance Score Analysis
=========================

Mean compliance (2023):       ___%
Median compliance (2023):     ___%
Min compliance (2023):        ___%
Max compliance (2023):        ___%
Std Dev (2023):               ___%

Mean compliance (2024):       ___%
Median compliance (2024):     ___%
Min compliance (2024):        ___%
Max compliance (2024):        ___%
Std Dev (2024):               ___%

Locations below 80% (2023):   ___ (requires follow-up)
Locations below 80% (2024):   ___ (requires follow-up)
```

**Section 5: Data Integrity Checks**

```
Data Integrity Validation
=========================

Check                              Status     Notes
─────────────────────────────────────────────────────────────
All audits linked to locations     PASS/FAIL
All audits linked to periods       PASS/FAIL
All required fields populated      PASS/FAIL
No duplicate audits                PASS/FAIL
Compliance scores calculated       PASS/FAIL
Location.LastAuditDate updated     PASS/FAIL
Defi brillator type matches        PASS/FAIL
Equipment count validations        PASS/FAIL

SIGNED OFF:
Data Steward: ________________ Date: __________
System Admin: ________________ Date: __________
```

---

## Part 5: Migration Execution Plan

### 5.1 Phase 3.3.1-3.3.5: 2023 Data Migration

**Tasks in this phase:**

| Task | Description | Duration | Owner |
|------|---|---|---|
| 3.3.1 | Analyze 2023 data structure | 1 day | Data Steward |
| 3.3.2 | Create location mapping document | 2 days | Data Steward |
| 3.3.3 | Build Power Query transformation | 2 days | Admin/Developer |
| 3.3.4 | Import 2023 records to Audit list | 1 day | Admin |
| 3.3.5 | Validate record counts and integrity | 1 day | Data Steward + Admin |

**Detailed Steps:**

**Task 3.3.1: Analyze 2023 Data Structure**

1. Obtain 2023 Microsoft Forms export (CSV or Excel)
2. Open in Power Query or Excel
3. Document findings:
   - Total record count (should be ~75)
   - Column names and data types
   - Sample values from each column
   - Data quality issues observed (see Section 1.3)
4. Create analysis document: `2023_Data_Analysis.txt`

**Task 3.3.2: Create Location Mapping Document**

1. Extract unique Clinical Area values from 2023 data
   ```sql
   SELECT DISTINCT [Clinical Area], COUNT(*)
   FROM 2023Data
   GROUP BY [Clinical Area]
   ORDER BY [Clinical Area]
   ```
2. For each unique name, search Location master list for match
3. Document in CSV: `location_name_mapping_2023.csv`
4. Flag any with Low confidence
5. Get approval from Data Steward before proceeding

**Task 3.3.3: Build Power Query Transformation**

1. Copy the Power Query script from Section 3.2
2. Update file paths to actual 2023 export location
3. Update LocationMappingTable with actual mappings from Task 3.3.2
4. Test on sample of 10 records
5. Verify output columns match target SharePoint schema
6. Fix any errors in M script
7. Run full transformation on complete dataset
8. Export to Excel or CSV

**Task 3.3.4: Import 2023 Records to Audit List**

**Option A: Using Power Automate Flow**

1. Create flow with trigger "Manually triggered"
2. Add action: "List rows present in a table" (Excel/CSV with transformed data)
3. For each row:
   - Look up LocationId from Location list
   - Look up PeriodId from AuditPeriod list (create 2023 period if needed)
   - Create new Audit record
   - Create AuditDocuments child record
   - Create AuditCondition child record
   - Create AuditChecks child record
   - Calculate and save OverallCompliance
4. Handle errors: send email alerts for failed records
5. Run flow
6. Monitor for completion

**Option B: Using SharePoint Bulk Operations**

1. Export transformed data to Excel
2. Copy/paste into Audit list through SharePoint UI
3. Use Power Apps Bulk Edit if available
4. Verify each record created correctly

**Option C: Using REST API**

1. Create Python script or PowerShell script
2. Read transformed data from CSV
3. For each row, POST to SharePoint REST endpoints
4. Handle authentication and error responses

**Task 3.3.5: Validate Record Counts and Integrity**

1. Execute all V1.1-V1.8 validation checks from Section 4.1
2. Document any issues found
3. For each issue:
   - Investigate root cause
   - Decide: Remediate, Flag for manual review, or Accept with note
4. If issues found, fix and re-import affected records
5. Generate validation report (Section 4.3)
6. Get sign-off from Data Steward and Admin

### 5.2 Phase 3.3.6-3.3.10: 2024 Data Migration

**Tasks in this phase:**

| Task | Description | Duration | Owner |
|---|---|---|---|
| 3.3.6 | Analyze 2024 data structure | 1 day | Data Steward |
| 3.3.7 | Create location mapping document | 1 day | Data Steward |
| 3.3.8 | Build Power Query transformation | 1 day | Admin/Developer |
| 3.3.9 | Import 2024 records to Audit list | 1 day | Admin |
| 3.3.10 | Validate record counts and integrity | 1 day | Data Steward + Admin |

**Detailed Steps:**

These are identical to Phase 3.3.1-3.3.5 with these modifications:

**Task 3.3.6: Analyze 2024 Data Structure**

- Same as 3.3.1
- Document: `2024_Data_Analysis.txt`
- Expected record count: ~76

**Task 3.3.7: Create Location Mapping Document**

- Same as 3.3.2
- Document: `location_name_mapping_2024.csv`
- May be similar to 2023, but check for new locations

**Task 3.3.8: Build Power Query Transformation**

- Copy 2023 script from Section 3.2
- Update file path to 2024 export
- Update LocationMappingTable with 2024 mappings
- Update year logic: should detect 2024 dates and use 2024 AuditPeriod

**Task 3.3.9: Import 2024 Records**

- Same process as 3.3.4
- Use same Power Automate flow or modify for 2024 data

**Task 3.3.10: Validate**

- Same validation checks as 3.3.5
- Compare results to 2023 metrics

### 5.3 Phase 3.3.11: Post-Migration Location Updates

**Task Description:**

Update Location master table with last audit date and compliance from imported historical data.

**Detailed Steps:**

```
FOR EACH Location in Location list:

  1. Query Audit list:
     SELECT MAX(CompletedDateTime) as LastAuditDate,
            OverallCompliance
     FROM Audit
     WHERE LocationId = current Location
     AND CompletedDateTime <= TODAY()
     ORDER BY CompletedDateTime DESC
     LIMIT 1

  2. IF result found:
     - Update Location.LastAuditDate = LastAuditDate
     - Update Location.LastAuditCompliance = OverallCompliance

  3. IF no result (location never audited):
     - Leave LastAuditDate = NULL
     - Leave LastAuditCompliance = NULL
     - DaysSinceLastAudit calculated column will show 999

  4. Verify Location.DaysSinceLastAudit calculated field
     Formula: =IF(ISBLANK([LastAuditDate]),999,DATEDIF([LastAuditDate],TODAY(),"D"))
     Should show correct number of days since last audit
```

**Power Automate Implementation:**

```
Flow Name: "Post-Migration Update Location LastAudit Fields"

Trigger: Manual

Step 1: Get all locations from Location list

Step 2: For each Location:
  - Query Audit list filtering by Location
  - Get most recent completed audit
  - Update Location record with:
    * LastAuditDate
    * LastAuditCompliance

Step 3: After all complete, generate report
  - Locations updated: ___
  - Locations with no audit history: ___
```

**SQL Query to Execute Manually (if using database view):**

```sql
UPDATE Location l
SET
  LastAuditDate = (
    SELECT MAX(a.CompletedDateTime)
    FROM Audit a
    WHERE a.LocationId = l.LocationId
    AND a.CompletedDateTime <= GETDATE()
  ),
  LastAuditCompliance = (
    SELECT a.OverallCompliance
    FROM Audit a
    WHERE a.LocationId = l.LocationId
    AND a.CompletedDateTime = (
      SELECT MAX(CompletedDateTime)
      FROM Audit
      WHERE LocationId = l.LocationId
      AND CompletedDateTime <= GETDATE()
    )
  )
WHERE Status = 'Active'
```

**Verification:**

After Task 3.3.11 completion, verify:

1. All 76 locations have been checked
2. Locations with audits now show LastAuditDate and LastAuditCompliance
3. No locations show future dates for LastAuditDate
4. DaysSinceLastAudit field calculates correctly
5. View "Overdue Audits" (DaysSinceLastAudit > 180) shows expected results

---

## Part 6: Troubleshooting Guide

### Issue: "Location lookup failed - no matching location found"

**Cause:** Clinical Area name in historical data doesn't match Location master title

**Solution:**
1. Check spelling and spacing in both systems
2. Update location_name_mapping.csv with exact name from Location master
3. Re-run Power Query transformation
4. Verify all locations in the mapping table exist in Location list

**Example:**
```
Historical: "Cath Lab"
Master: "Cath Lab procedure room 1"
Fix: Add mapping: "Cath Lab" → "Cath Lab procedure room 1"
```

### Issue: "Check count exceeds realistic maximum"

**Cause:** Data entry error or cumulative count instead of period count

**Solution:**
1. Investigate the specific record
2. If data error, correct in transformed dataset
3. If legitimate high count, document reason in audit notes
4. Re-import corrected records

### Issue: "Compliance score is 0% or 100% for all records"

**Cause:** Formula error or incomplete data mapping

**Solution:**
1. Verify all transformation steps completed correctly
2. Check Power Automate compliance calculation formula
3. Test on single record and debug
4. Re-run formula for all records

### Issue: "Some dates show as "Not Available" or 1900"

**Cause:** Date conversion failed in Power Query

**Solution:**
1. Check source data date format
2. Update Power Query DateTime conversion logic
3. Add error handling in M script:
   ```powerquery
   else try Value.FromText(Text.Trim([OutsideCheckCount])) otherwise null
   ```
4. Re-run transformation

### Issue: "Audit records created but LocationId lookup is empty"

**Cause:** Lookup column not properly configured in Power Automate

**Solution:**
1. In Power Automate flow, ensure Location lookup action:
   ```
   Get Location by Title
   WHERE Title equals LocationName (from transformed data)
   ```
2. Store LocationId in variable before creating Audit
3. Test with single record
4. Re-create all Audit records if needed

---

## Part 7: Success Criteria and Sign-Off

### 7.1 Successful Migration Metrics

A successful Phase 3.3 migration demonstrates:

| Metric | Target | Actual | Status |
|--------|--------|--------|--------|
| 2023 records imported | 75 | ___ | PASS/FAIL |
| 2024 records imported | 76 | ___ | PASS/FAIL |
| Location match success rate | 100% | __% | PASS/FAIL |
| AuditPeriod lookup success | 100% | __% | PASS/FAIL |
| Data validation errors | <2% | __% | PASS/FAIL |
| Compliance scores calculated | 100% | __% | PASS/FAIL |
| Location.LastAuditDate populated | 100% | __% | PASS/FAIL |
| No duplicate audits | 0 | ___ | PASS/FAIL |
| Required fields present | 100% | __% | PASS/FAIL |
| Date ranges valid | 100% | __% | PASS/FAIL |

### 7.2 Migration Sign-Off

Upon completion of all Phase 3.3 tasks, obtain written approval:

```
PHASE 3.3 MIGRATION SIGN-OFF
============================

Project: REdI Trolley Audit System
Phase: 3.3 Historical Data Migration
Completion Date: _______________

COMPLETED TASKS:
✓ Task 3.3.1: 2023 data analyzed
✓ Task 3.3.2: 2023 location mapping created
✓ Task 3.3.3: 2023 Power Query transformation built
✓ Task 3.3.4: 2023 records imported
✓ Task 3.3.5: 2023 validation completed

✓ Task 3.3.6: 2024 data analyzed
✓ Task 3.3.7: 2024 location mapping created
✓ Task 3.3.8: 2024 Power Query transformation built
✓ Task 3.3.9: 2024 records imported
✓ Task 3.3.10: 2024 validation completed

✓ Task 3.3.11: Post-migration location updates completed

VALIDATION REPORT: APPROVED/REJECTED

Data Quality Issues Resolved: ______
Remaining Known Issues: ____________

This migration is APPROVED FOR PRODUCTION deployment.

Approved By:

Data Steward: __________________ Date: __________
System Admin: __________________ Date: __________
MERT Educator (Sponsor): ________ Date: __________

```

---

## Appendix A: Location Name Mapping Template

Save as `location_name_mapping.csv` and populate before import.

```csv
HistoricalName,MasterLocationName,ServiceLine,Building,Level,MatchConfidence,Notes
4C Burns Unit,4C Burns Unit,Surgical & Perioperative Services,James Mayne Building,Level 4,High,
5c,5C beds 1-18,Cancer Care Services,Joyce Tweddell Building,Level 5,High,Both 5C areas combined
5C,5C beds 1-18,Cancer Care Services,Joyce Tweddell Building,Level 5,High,
5C beds,5C beds 1-18,Cancer Care Services,Joyce Tweddell Building,Level 5,High,
5C beds 1-18,5C beds 1-18,Cancer Care Services,Joyce Tweddell Building,Level 5,High,
5C beds 19-22,5C beds 19-22,Cancer Care Services,Joyce Tweddell Building,Level 5,High,
6A North,6A North (including Gynae),Internal Medicine Services,Ned Hanlon Building,Level 6,High,
6A South,6A South,Cancer Care Services,Ned Hanlon Building,Level 6,High,
```

---

## Appendix B: Power Automate Flow Template

For teams using Power Automate to import transformed data:

```
Flow: Import Historical Audit Data

Trigger:
  - Manually triggered button

Inputs:
  - DataSourcePath (path to transformed CSV)
  - ImportYear (2023 or 2024)

Steps:
  1. Initialize variables
     - successCount = 0
     - failCount = 0
     - errorList = empty array

  2. Read transformed data from CSV
     Action: "Excel Online (Business)" → "List rows present in a table"

  3. For each row in data:
     a. Look up Location
        Action: Get items from Location list
        Filter: Title equals [LocationName]
        Store LocationId in variable

     b. Look up AuditPeriod
        Action: Get items from AuditPeriod list
        Filter: Title equals [AuditPeriodName]
        Store PeriodId in variable

     c. Condition: If LocationId and PeriodId found
        - Create Audit record
        - Create AuditDocuments record
        - Create AuditCondition record
        - Create AuditChecks record
        - Calculate OverallCompliance
        - Increment successCount

     d. Condition: Else (lookups failed)
        - Add error to errorList
        - Increment failCount

  4. Update Location records
     For each Location with new audits:
     - Get most recent audit
     - Update Location.LastAuditDate
     - Update Location.LastAuditCompliance

  5. Send summary email
     To: Data Steward
     Subject: "Historical Audit Import Complete"
     Body: "Success: {successCount}, Failed: {failCount}, Errors: {errorList}"

Output:
  - Total records processed
  - Success count
  - Failure count
  - Error list for manual review
```

---

## Appendix C: Sample Validation Queries

SQL queries to validate migrated data. Execute in your database tool or SharePoint REST API explorer.

```sql
-- Count imported records by year
SELECT
  YEAR(a.CompletedDateTime) as AuditYear,
  COUNT(*) as RecordCount,
  COUNT(DISTINCT a.LocationId) as UniqueLocations,
  AVG(a.OverallCompliance) as AvgCompliance
FROM Audit a
WHERE a.SubmissionStatus = 'Submitted'
GROUP BY YEAR(a.CompletedDateTime)
ORDER BY AuditYear

-- Find locations with multiple audits in same year
SELECT
  l.Title as LocationName,
  YEAR(a.CompletedDateTime) as AuditYear,
  COUNT(*) as AuditCount,
  MIN(a.CompletedDateTime) as FirstAudit,
  MAX(a.CompletedDateTime) as LastAudit
FROM Audit a
JOIN Location l ON a.LocationId = l.LocationId
WHERE a.SubmissionStatus = 'Submitted'
GROUP BY l.Title, YEAR(a.CompletedDateTime)
HAVING COUNT(*) > 1
ORDER BY LocationName, AuditYear

-- Compliance score distribution
SELECT
  CASE
    WHEN a.OverallCompliance >= 90 THEN '90-100%'
    WHEN a.OverallCompliance >= 80 THEN '80-90%'
    WHEN a.OverallCompliance >= 70 THEN '70-80%'
    WHEN a.OverallCompliance >= 60 THEN '60-70%'
    ELSE 'Below 60%'
  END as ComplianceRange,
  COUNT(*) as RecordCount
FROM Audit a
WHERE a.SubmissionStatus = 'Submitted'
GROUP BY
  CASE
    WHEN a.OverallCompliance >= 90 THEN '90-100%'
    WHEN a.OverallCompliance >= 80 THEN '80-90%'
    WHEN a.OverallCompliance >= 70 THEN '70-80%'
    WHEN a.OverallCompliance >= 60 THEN '60-70%'
    ELSE 'Below 60%'
  END
ORDER BY ComplianceRange DESC

-- Data quality check: records with missing critical fields
SELECT
  COUNT(*) as RecordsWithIssues,
  SUM(CASE WHEN AuditorName IS NULL OR AuditorName = '' THEN 1 ELSE 0 END) as MissingAuditorName,
  SUM(CASE WHEN LocationId IS NULL THEN 1 ELSE 0 END) as MissingLocation,
  SUM(CASE WHEN PeriodId IS NULL THEN 1 ELSE 0 END) as MissingPeriod,
  SUM(CASE WHEN OverallCompliance IS NULL THEN 1 ELSE 0 END) as MissingCompliance
FROM Audit
WHERE SubmissionStatus = 'Submitted'
```

---

## Document Version Control

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0 | Jan 2026 | Documentation Team | Initial comprehensive guide for Phase 3.3 |

---

**Document Prepared For:** REdI Team
**Contact:** MERT Nurse Educator or System Administrator
**Classification:** Internal Use - Implementation Guide

